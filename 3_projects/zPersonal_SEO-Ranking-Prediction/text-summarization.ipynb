{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import jieba\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "eng_words = set(nltk.corpus.words.words())\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.decomposition import PCA\n",
    "from urllib.parse import unquote\n",
    "# from gensim.test.utils import common_texts, get_tmpfile\n",
    "# from gensim.models import Word2Vec\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_keyword = 'seo 公司'\n",
    "num = 50\n",
    "\n",
    "####設定停用詞\n",
    "# cn_stopwords = pd.read_csv('cn_stopwords.csv')['$'].values.tolist()\n",
    "# 更完整的停用詞庫: https://github.com/tomlinNTUB/Machine-Learning/blob/master/data/%E5%81%9C%E7%94%A8%E8%A9%9E-%E7%B9%81%E9%AB%94%E4%B8%AD%E6%96%87.txt\n",
    "file = open('cn_stopwords.txt', 'r', encoding='utf-8')\n",
    "try:\n",
    "    content = file.read()\n",
    "    cn_stopwords = content.split('\\n')\n",
    "finally:\n",
    "    file.close()\n",
    "    \n",
    "exclude_cn_marks = ['〈', '〉','＜','＞','《','》','｛','｝','﹛','﹜','［','］','「','」','『','』','【','】','〔','〕','。','，','、','；','：','»','｜','！','？','–','…','©']\n",
    "for char in exclude_cn_marks:\n",
    "    cn_stopwords.append(char)\n",
    "\n",
    "file = open('eng_stopwords.txt', 'r')\n",
    "try:\n",
    "    content = file.read()\n",
    "    eng_stopwords = content.split(',')\n",
    "finally:\n",
    "    file.close()\n",
    "\n",
    "# https://blog.csdn.net/linshenwei1995/article/details/78987444\n",
    "exclude_marks = ['/','\\\\','>','<','»','->','!','@','#','$','^','&','*','(',')','-','=','+','{','}','[',']','|',';',':','.','..','...',',','?','~','`',\"'\",'\\n','\\r\\n','\\xa0']\n",
    "for char in exclude_marks:\n",
    "    eng_stopwords.append(char)\n",
    "\n",
    "all_stopwords = list()\n",
    "for char in cn_stopwords:\n",
    "    all_stopwords.append(char)\n",
    "for char in eng_stopwords:\n",
    "    all_stopwords.append(char)\n",
    "    \n",
    "all_marks = exclude_cn_marks + exclude_marks\n",
    "\n",
    "####啟動 tf-idf 計算函式\n",
    "# vectorizer = TfidfVectorizer(analyzer='word', stop_words=all_stopwords)#, max_df=1.0, min_df=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>article_keywords</th>\n",
       "      <th>article_content</th>\n",
       "      <th>article_published_time</th>\n",
       "      <th>article_modified_time</th>\n",
       "      <th>article_schema</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.da-vinci.com.tw/tw/blog/seo-cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>搜尋 搜尋 f TW TW CN 首頁 關於我們 公司介紹 專業團隊 服務項目 網頁設計 網...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEO收費行情？該怎麼選擇SEO公司?-SEO優化-部落格-達文西 ...</td>\n",
       "      <td>2020年3月17日 - 大家都在討論SEO關鍵字排名，市場報價非常紊亂，比網頁設計更沒有報...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           link  article_keywords  \\\n",
       "0  https://www.da-vinci.com.tw/tw/blog/seo-cost               NaN   \n",
       "\n",
       "                                     article_content article_published_time  \\\n",
       "0  搜尋 搜尋 f TW TW CN 首頁 關於我們 公司介紹 專業團隊 服務項目 網頁設計 網...                    NaN   \n",
       "\n",
       "  article_modified_time  article_schema  \\\n",
       "0                   NaN             NaN   \n",
       "\n",
       "                                   title  \\\n",
       "0  SEO收費行情？該怎麼選擇SEO公司?-SEO優化-部落格-達文西 ...   \n",
       "\n",
       "                                                desc  \n",
       "0  2020年3月17日 - 大家都在討論SEO關鍵字排名，市場報價非常紊亂，比網頁設計更沒有報...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sub_marks(x):\n",
    "    text_list = list(x)\n",
    "    new_list = list()\n",
    "    for char in text_list:\n",
    "        if char not in all_marks:\n",
    "            new_list.append(char)\n",
    "        else:\n",
    "            new_list.append(' ')\n",
    "    return ''.join(new_list)\n",
    "\n",
    "page_data = pd.read_csv('SERP_{}_num_{}.csv'.format(search_keyword, num))\n",
    "df = pd.read_csv('{}_{}_articles_features.csv'.format(search_keyword, num))\n",
    "df = pd.concat([df.iloc[:, np.r_[0, 2:7]], page_data.iloc[:, :2]], axis=1)\n",
    "# df['link'] = df['link'].apply(lambda x: unquote(x).lower())\n",
    "# df['article_content'] = df['article_content'].apply(lambda x: sub_marks(x.lower()))\n",
    "# df['title'] = df['title'].apply(lambda x: sub_marks(x.lower()))\n",
    "# df['desc'] = df['desc'].apply(lambda x: sub_marks(x.lower()))\n",
    "# df['web_content_feature'] = df['article_content']+' '+(df['link']+' ')*30+' '+(df['title']+' ')*20+' '+(df['desc']+' ')*2\n",
    "\n",
    "print(df.shape)\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to sentence \n",
    "- delimiter: 。, ？, ！, ?, !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1798,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'搜尋 搜尋 f TW TW CN 首頁 關於我們 公司介紹 專業團隊 服務項目 網頁設計 網頁設計服務 客製網頁設計 套版網頁設計 Da-系列服務 Da-Video 影音網 Da-Shop 購物網 主機服務 網站代管 其他服務 SEO全網站優化 EDM主動行銷 商業攝影 設計作品 常見問答 網頁設計 SEO網站優化 網站主機代管 Da-Video 影音網 Da-Shop 購物網 部落格 網頁設計 網路行銷 SEO優化 工商服務 聯絡我們 BLOG 首頁 部落格 SEO收費行情'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_content'] = df['article_content'].apply(lambda x: re.split('[。？！?!]', str(x)))  # https://stackoverflow.com/questions/4998629/split-string-with-multiple-delimiters-in-python\n",
    "\n",
    "sentences = list()\n",
    "\n",
    "# for article in df['article_content'].values:\n",
    "#     sentences.append(sent_tokenize(article))\n",
    "\n",
    "for item_list in df['article_content'].values:\n",
    "    for item in item_list:\n",
    "        if (item != '') and (item != ' '):\n",
    "            sentences.append(item)\n",
    "\n",
    "np.array(sentences).shape\n",
    "sentences[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean each sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'搜尋 搜尋 f tw tw cn 首頁 關於 我們 公司 介紹 專業 團隊 服務 項目 網頁 設計 網頁 設計 服務 客 製 網 頁 設 計 套版 網頁 設計 da 系列 服務 da video 影音 網 da shop 購物網 主機 服務 網站 代管 其他 服務 seo 全網 站 優化 edm 主動 行銷 商業 攝影 設計 作品 常見 問答 網頁 設計 seo 網站 優化 網站 主機 代管 da video 影音 網 da shop 購物網 部落 格 網頁 設計 網路 行銷 seo 優化 工商 服務 聯絡 我們 blog 首頁 部落 格 seo 收費 行情'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = sentences[:62]\n",
    "test_sentences = [sub_marks(x.lower()) for x in test_sentences]\n",
    "\n",
    "def jieba_cut_in_sentence(x):\n",
    "    _list = list()\n",
    "    for char in jieba.cut(x, cut_all=False):\n",
    "        if ((x.strip() != '') and (x.strip() not in all_stopwords) and (any(char.isdigit() for char in x.strip()) == False)):\n",
    "            _list.append(char)\n",
    "    \n",
    "    return _list\n",
    "            \n",
    "test_sentences = [' '.join([x for x in jieba_cut_in_sentence(x) if x != ' ']) for x in test_sentences]\n",
    "test_sentences[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding: GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = {}\n",
    "f = open('glove.6B/glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    vs = line.split()\n",
    "    word = vs[0]\n",
    "    coefs = np.asarray(vs[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n",
    "\n",
    "len(word_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create vectors from cleaned sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-112-25e181702741>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-112-25e181702741>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    for sent in test_sentences;\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sentence_vectors = list()\n",
    "\n",
    "for sent in test_sentences:\n",
    "    if len(sent) != 0:\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b7246eb0bbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m### 現在問題：GloVe只有英文單詞的embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "word_embeddings.get('seo', np.zeros((100,)))\n",
    "\n",
    "### 現在問題：GloVe只有英文單詞的embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
